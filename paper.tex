\documentclass[10pt, conference, compsocconf]{IEEEtran}

% packages
\usepackage{algorithm}
\usepackage{algorithmic}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
%\usepackage{algpseudocode}
\usepackage{amsfonts} % for R symbol (the set of real numbers)
\usepackage{color}
\usepackage[pdftex]{graphicx}
\usepackage{graphicx}
\usepackage[bookmarks=false]{hyperref}
\hypersetup{colorlinks=true,linkcolor=black,citecolor=black,filecolor=black,urlcolor=blue}
\usepackage{mathtools}
\usepackage{multirow}
\usepackage{stmaryrd} % for llbracket and rrbracket
\usepackage{subcaption}
\usepackage{nicefrac}
\usepackage{amsmath}
\usepackage{amssymb}
\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
\DeclarePairedDelimiter{\floor}{\lfloor}{\rfloor}

% new commands
\newcommand{\todo}[1]{\marginpar{\parbox{18mm}{\flushleft\tiny\color{red}\textbf{TODO}:
      #1}}}
\newcommand{\note}[1]{
  \color{blue}\emph{[Note: #1]}
  \color{black}
}

\begin{document}

\title{A multi-dimensional extension of the Lightweight Temporary Compression method}

\author{Bo Li, Tristan Glatard\\
  Department of Computer Science and Software Engineering\\ Concordia University, Montreal, Quebec, Canada\\
  {first.last}@concordia.ca \vspace*{-0.5cm}}

\maketitle

\begin{abstract}
\end{abstract}

\section{Introduction}

LTC is among the stream compression method that provides the highest
compression rate for the lowest resource (CPU, RAM) consumption. As
such, it makes it a very good candidate for the compression of data
streams acquired in embedded, low-power systems such as connected
objects, systems on module (SoMs), etc The type of data acquired on
such systems, however, is often multi-dimensional. For instance
accelerometers and gyroscopes usually measure variables along 3
directions, these variables being distinct but related through the
actual movement of the sensor. In this paper, we investigate the
extension of LTC to higher dimensions. First, we express the algorithm
in an arbitrary vectorial space of dimension $n$. Second, we
instantiate it for the Euclidean and xxx distances, in spaces of
dimension 2D+t and 3D+t. Finally, we compare the multi-dimensional LTC
to the 1-dimensional version, on gyroscopic data acquired on a SoM
device.

\section{Lightweight Temporal Compression}

Summarize existing paper.

Lightweight temporal compression (LTC) is one of the linear estimation
 method to compress data. It is The first-order interpolator with two
degrees of freedom(FOI-2DF) which is mentioned in ~\cite{jalaleddine1990ecg}.
Most of linear estimation method need a predefined parameter which is
the error margin (let's call $\epsilon$) in order to guarantee the
difference between estimation and original data within a scope.

\todo{rewrite LTC algorithm, and there is a DP version of LTC maybe should also be written}

\section{Extension to dimension $n$}


In practice, It's needed to transmit raw data which has multi-parameters
to clients e.g. Accelerometer, Euler Angle and Magnetometer etc.
Most of previous paper just force on single dimension sensor
data Compression. So we purpose a method to compress multi-dimensional
sensor data named LTC-D. It is used as linear estimation method.
Same as usual estimation compression method,  distance(different)
with compressed data from LTC-D and original data would not exceed
the predefined error range. We need to find line to represent
original data, it means the lines pass through datas' error range.
But in stream data, time seires data, it is difficult, because
all data do not show in same time plane. So this method will
mapping all data into one time plane. Then for each mapped error
range of data, check if there is intersection among them. If so means
there is a line could represent original data, and vice versa.

The method as below: assume the stream $i_{th}$ data
$D_i = (x_{i1}, x_{i2}, ..., x_{in},t_i)$, the first data $D_0$ would
be save as base point $Z=(z_{1}, z_{2}, ..., z_{n},t_z)$in the Method.
As usual, the timestamp after basepoint would be set as mapping plane.
We also need to record the intersect $S$ for find result lines.
The first data $D_1$ would change into tolerance range $R_1$.
initializing $S = R_1$. For each follow data$ D_i, i>1$, mapping $D_1$
into $\hat{D_1}$ = $(\{\hat{x_{ij}}=z_j + \frac{x_{ij}-z_{j}}{t_i-t_z} \mid1\leqslant{j}\leqslant{n}\},t_i)$,
and error margin after mapping should be $\frac{\epsilon}{t_i-t_z}$
on $\hat{x_{ij}}, j={1...n}$. The tolerance range after R_i, intersect
with S, if there is overlap, update S = S intersect R_i. If not, the base point
would be transmited and select a point in S as base point with timestamp $t_{i-1}$.

\todo{refector}
At beginning of the algorithm, we need a base point (which we will call \textit{z}) and bounding box which has upper and lower bound for each parameter respectively.Then start the algorithm.
\begin{enumerate}
  \item Initialization: Get first data point, and set point \textit{z} equals to first data point. Get the second data point $(x_{21},...,x_{2n},t_2)$, and assign each upper bound $U_j = x_{2j}+\frac{\epsilon}{t_2-t_1}$ and lower bound $L_j = x_{2j}-\frac{\epsilon}{t_2-t_1}$ where $j=\{1...n\}$.
  \item Get next data point, map the data point $(x_{i1},...,x_{in},t_i)$ into $(\{\hat{x_{ij}}=z_j + \frac{x_{ij}-z_{j}}{t_i-t_z} \mid1\leqslant{j}\leqslant{n}\},t_i)$.
  \item For each parameter(dimension) \textit{j}, if upper bound $U_j$ smaller than $x_{ij}-\frac{\epsilon}{t_i-t_1}$ or lower bound $L_j$ bigger than $x_{ij}+\frac{\epsilon}{t_i-t_1}$, then \textbf{goto 5}, else $U_j = min(U_j, x_{ij}+\frac{\epsilon}{t_i-t_1})$, and $L_j = max(L_j, x_{ij}-\frac{\epsilon}{t_i-t_1})$.
  \item Goto 2.
  \item output \textit{z} data point.
  \item Reset: set data point \textit{z} equals to center of the bounding box with time-stamp $t_{i-1}$, and $U_j=x_{ij}+\frac{\epsilon}{t_i-t_{i-1}}$, $L_j =x_{ij}-\frac{\epsilon}{t_i-t_{i-1}}$ with $j=\{1...n\}$.
  \item Goto 2.
  \item After all, output \textit{z} data point and center of bounding box respectively.
\end{enumerate}

for tolerance range, it depends on EPSILON and different type of distances for EPSILON.
If we using Manhattan distance to create tolerance range, it would become rectangle in 2D and cube for 3D.
But the tolerance range wold become disk or ball in 2D and 3D respectively, by using Euclidean distance.
\todo{maybe need a graphic}




In practice, It's needed to transmit raw data which has multi-parameters to clients e.g. Accelerometer, Euler Angle and Magnetometer etc. LTC not work well when we transmit multi-parameters data, cause if we just implement LTC for each parameter, the difference between estimation and origin could exceed error margin which was set in advance. For instance, there is a data $(x, y)$ with two parameters, and using LTC for both parameter respectively. According to LTC method $\mid{\hat{x}-x}\mid\leqslant \epsilon$~\cite{jalaleddine1990ecg}, the estimation may be $(\hat{x}=x+\epsilon, \hat{y}=y+\epsilon)$, then the difference between estimation and original data $(x,y)$ is which is bigger than error margin predefined. In this case, we design a new algorithm, which is multi-parameter version of LTC, and it also work with any type of distance. In standard LTC method, it checks if there is overlapping part between new sector area and recorded range. However, in our multidimensional method, we will map every data point into same time-stamp e.g. $t_0$. It is convenient for us to calculate distance between them and check if overlapping range exists. we provide Multidimensional-LTC with Euclidean and Manhattan distance in below.

\section{Implementation}
Our code is available at ... (make a clean release!)
/todo{below content is useful? }
\subsection{Multidimensional LTC with Manhattan distance}
In practice, Multidimensional LTC is same as implementing LTC in each parameter respectively. But we did some changes in our method. Assume $(x_{i1}, x_{i2}, ..., x_{in},t_i)$ is the $i_{th}$ coming data with n-dimension, and a base data point Z  $(z_{1}, z_{2}, ..., z_{n},t_z)$~\cite{schoellhammer2004lightweight}. We map each coming data to $t_1$ time-stamp and create a bounding box for recording overlapping range which includes upper and lower bound for each dimension base on $t_1$. cause the time different between two adjacent data, so the $i_th$ data after mapping is $(\{\hat{x_{ij}}=z_j + \frac{x_{ij}-z_{j}}{t_i-t_z} \mid1\leqslant{j}\leqslant{n}\},t_i)$.
After that updating tolerance range by adding designed error margin which after mapping
$\frac{\epsilon}{t_i-t_z}$ on $\hat{x_{ij}}, j={1...n}$ with Manhattan distance. checking if there is overlap between tolerance and bounding box.The algorithm is as follows.

\note{not clear about Manhattan distance, in my opinion for each axis the distance less than $EPSILON/t_i-t_0$ + bounding box length}

At beginning of the algorithm, we need a base point (which we will call \textit{z}) and bounding box which has upper and lower bound for each parameter respectively.Then start the algorithm.
\begin{enumerate}
  \item Initialization: Get first data point, and set point \textit{z} equals to first data point. Get the second data point $(x_{21},...,x_{2n},t_2)$, and assign each upper bound $U_j = x_{2j}+\frac{\epsilon}{t_2-t_1}$ and lower bound $L_j = x_{2j}-\frac{\epsilon}{t_2-t_1}$ where $j=\{1...n\}$.
  \item Get next data point, map the data point $(x_{i1},...,x_{in},t_i)$ into $(\{\hat{x_{ij}}=z_j + \frac{x_{ij}-z_{j}}{t_i-t_z} \mid1\leqslant{j}\leqslant{n}\},t_i)$.
  \item For each parameter(dimension) \textit{j}, if upper bound $U_j$ smaller than $x_{ij}-\frac{\epsilon}{t_i-t_1}$ or lower bound $L_j$ bigger than $x_{ij}+\frac{\epsilon}{t_i-t_1}$, then \textbf{goto 5}, else $U_j = min(U_j, x_{ij}+\frac{\epsilon}{t_i-t_1})$, and $L_j = max(L_j, x_{ij}-\frac{\epsilon}{t_i-t_1})$.
  \item Goto 2.
  \item output \textit{z} data point.
  \item Reset: set data point \textit{z} equals to center of the bounding box with time-stamp $t_{i-1}$, and $U_j=x_{ij}+\frac{\epsilon}{t_i-t_{i-1}}$, $L_j =x_{ij}-\frac{\epsilon}{t_i-t_{i-1}}$ with $j=\{1...n\}$.
  \item Goto 2.
  \item After all, output \textit{z} data point and center of bounding box respectively.
\end{enumerate}

\subsection{Multidimensional LTC with Euclidean distance}
In Euclidean distance version, we also map the coming data into same time-stamp $t_1$ the timestamp after base point. The difference with Manhattan distance version is that recording overlapping part with a post-designed model is difficult, which need retain several arcs in 2-dimension, or convex surfaces in 3-dimension. In our method, we will record all tolerance range for every mapped data which come from base data point until coming data point, in order to checking if there is intersection among them. For instance, in 3D-t, assume we have a the base point $Z = D_0$ and the tolerance range $R_1$ which is a ball as the intersection S. we need a list L to record mapped balls from $D_1$ to coming data. For each comming data $D_i, i>1$ mapping this data into $t_1$, and add it into list. Then the work is check out if all balls intersect, and form a public intersection. The method is based on plane sweep and binary search. At first, select one parameter, such as x-axis, finding a bounding range of all balls $B_i$ in x-axis. suppose $Max_bound_x = Min{1..n}{B_i.center.x + EPSILON/i}$, and $Min_bound_x = Max{1..n}{B_i.center.x - EPSILON/i}$. If there is overlap among balls, then the axis of the points inside intersection must located between Min_bound_x and Max_bound_x. Using binary search to select mid_x = (Min_bound_x + Max_bound_x)/2, then calculate a y-axis bounding with the plane x = mid_x. If the get bounding range in y-axis where $Max_bound_y > Min_bound_y$ and using binary search again to find mid_y, It means there is a line x=mid_x, Max_bound_y>= y >= Min_bound_y, parallels z-axis, could pass through all balls. Finally, in z-axis, compute bounding range, and If $Max_bound_z > Min_bound_z$, there must be one or more points inside all balls. The problem be solved. If the loop of binary search in x-axis overs, then there is no public intersection among balls, and need to transmit and update base point. In this method we need O(n*logn*logn) time complexity for binary search in x-axis and y-axis and traversal all balls in z-axis, also O(n) space complexity is needed for maintaining list. According this method, it could be extended into N-dimensional data. The main idea is to search, dimension by dimension, from a room or plane or line and get intersection point finally.

/todo{below content is useful? }
In the rest of this section, we describe examples for 2-dimensional and 3-dimensional version. After that, we extend the method for n-dimension.
\begin{itemize}
\item \textbf{2-dimensional LTC in Euclidean distance:}In this situation, the tolerance range after mapping is a disk. After initializing base data point \textit{z}, for each coming data point need to be mapped into a same time-stamp, and heck if there is a intersection amount disks in disks set and new mapped coming data. Therefore, a algorithm is need to determine whether \textit{n} disks intersect or not.
\item \textbf{3-dimensional LTC in Euclidean distance:}In 3-dimension, cause of the preassigned error margin, the disks become balls with one extra axis. So In 3-dimension whether \textit{n} balls intersect need to be check.
\end{itemize}

At first, let us solve the \textit{n} disks intersect. We use a algorithm which is based on plane sweep and dichotomy. Assume a disk include center$(x,y)$ and radius $r$. The pseudo-code in Algorithm 1.

The main idea of the algorithm is, remove the bigger disk who contains mapped coming disk. It maybe increase Computational efficiency in the rest of algorithm, cause mapped coming disk is the smallest one than all in list of disks. Then we make a bounding range for x-axis and select a x-value $mid$ by using dichotomy method in order to calculate if a point $(y, mid)$ is included all disks. The complexity of this algorithm is $O(n)+O(n\log\epsilon) = O(n\log\epsilon)$.

For 3-dimension, assume data point like $(x, y, z)$ also need time-stamp t, we can also use above method by selecting $x$ and $y$ with dichotomy method and then check if there are points $(mid\_x, mid\_y, z)$ included by all balls. It needs $O(\log^2\epsilon)$ to determine $mid\_x, mid\_y$, and $O(n)$ to traverse all balls in list and calculate $z$. So 3-dimensional method need $O(n \log^2\epsilon)$ totally. If we extend this idea for n-dimension, suppose that the coming data is $(x_1,x_2,...,x_n)$ and the mapped data is a object with center $(d_1,d_2,...d_n)$ and radius $r$. The pseudo-code would show like Algorithm 2.

\section{Results}
\todo{ result table ?}
\subsection{Experiment 1: Pilot tests on Computer}
\begin{itemize}
    \item Data set: 5-times bicep curl which includes 613 data;
                    Mohammad Lateral bicep curl which include 41428 data;
                    All data is collected from Neblina, with 50Hz sampling of Sensors.
                    Using Valgrind massif measure memory usage. And using 'gettimeofday()' function in 'sys/time.h' for measure processing time usage.
    \item Experiment Condition: Fedora 64-bit system with 16G memory, i5-3210M CPU @ 2.50GHz Ã— 4. For each data set, we change number of Dimension and EPSILON.
    \item Result: Result shows in table.
    \item Conclusion: From the table, The LTC-Manhattan has higher compression radio. But LTC-Euclidean make sure the Max Error between reconstructed data and original data under EPSILON.Compression ratios would decrease with changing EPSILON smaller.
\end{itemize}

\subsection{Experiment 1: energy reduction on the Neblina}

The capacity of battery in Neblina is 100mAh, and the battery usage would not change too much, because it contans others fusion method which will running when turning on the Neblina.
In 50Hz sensor sampling rate, the average usage electric current for transmit accelerometers data is 2.0mA. It means Neblina could tranmit accelerometers data constantly in 100/2.0=50 hours.
After compressed by LTC-Manhattan method, the average usage electric current is 1.95mA. It just extend Neblina lift abou 1.28 hours.
But in 200Hz sampling rate. The electric before and after compression are 3.5 and 2.9 respectively. The running time of Neblina would be extended about 5.9 hours/

\begin{itemize}
    \item Data set: human activities, running, walking, jogging and work behind desk.
    \item Experiment Condition: work with neblina.
    \item Result:
    \item Conclusion:
\end{itemize}



The transform rate of Neblina is 50Hz.
\\
5-times bicep curl from Neblina. It includes 613 data which produced in 12.28 seconds.
\\
Mohammad Lateral bicep data which include 41428, produced in proximate 14 minutes.

\subsection{Compression ratios}

\subsection{Errors}

\subsection{Memory consumption}

\section{Conclusion}

\section*{Acknowledgement}
\begin{table}[]
    \begin{tabular}{|l|l|l|l|l|l|l|l|l|}
    \hline
    \multicolumn{9}{|l|}{Dimension 2}                                                                                                                         \\ \hline
    Data set               & \multicolumn{4}{l|}{5-times bicep curl}                        & \multicolumn{4}{l|}{Mohammad Lateral bicep}                     \\ \hline
    Distance               & \multicolumn{2}{l|}{Manhattan} & \multicolumn{2}{l|}{Eclidean} & \multicolumn{2}{l|}{Manhattan} & \multicolumn{2}{l|}{Euclidean} \\ \hline
    Epsilon                & 100          & 100/$\sqrt{2}$  & 100         & 100/$\sqrt{2}$  & 100        & 100/$\sqrt{2}$    & 100        & 100/$\sqrt{2}$    \\ \hline
    Max Error              & 127.63       & 94.46           & 99.63       & 70.47           & 140.70     & 99.73             & 99.99      & 70.71             \\ \hline
    Compression Radio      & 29.03\%      & 20.88\%         & 25.12\%     & 19.57\%         & 60.17\%    & 51.59\%           & 57.75\%    & 48.86\%           \\ \hline
    Max memory Usage(peak) & 80B          & 80B             & 432B        & 240B            & 80B        & 80B               & 2.1KB      & 1.3KB             \\ \hline
    Time Usage(Total)      & 0.103ms      & 0.082ms         & 0.220ms     & 0.200ms         & 5.70ms     & 4.85ms            & 20.04ms    & 19.28ms           \\ \hline
    \end{tabular}
\end{table}

\begin{table}[]
    \begin{tabular}{|l|l|l|l|l|l|l|l|l|}
    \hline
    \multicolumn{9}{|l|}{Dimension 3}                                                                                                                         \\ \hline
    Data set               & \multicolumn{4}{l|}{5-times bicep curl}                        & \multicolumn{4}{l|}{Mohammad Lateral bicep}                     \\ \hline
    Distance               & \multicolumn{2}{l|}{Manhattan} & \multicolumn{2}{l|}{Euclidean} & \multicolumn{2}{l|}{Manhattan} & \multicolumn{2}{l|}{Euclidean} \\ \hline
    Epsilon                & 100          & 100/$\sqrt{3}$  & 100         & 100/$\sqrt{3}$  & 100        & 100/$\sqrt{3}$    & 100        & 100/$\sqrt{3}$    \\ \hline
    Max Error              & 141.66       & 85.40           & 99.94       & 56.89           & 168.95     & 97.01             & 99.99      & 57.73             \\ \hline
    Compression Radio      & 23.00\%      & 12.89\%         & 18.43\%     & 9.95\%          & 51.13\%    & 37.17\%           & 46.05\%    & 32.63\%           \\ \hline
    Max memory Usage(peak) & 112B         & 112B            & 384B        & 256B            & 112B       & 112B              & 4.9KB      & 3.0KB             \\ \hline
    Time Usage(Total)      & 0.119ms      & 0.094ms         & 0.230ms     & 0.200ms         & 8.50ms     & 7.07ms            & 26.41ms    & 21.26ms           \\ \hline
    \end{tabular}
\end{table}


\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,biblio.bib}


\end{document}
